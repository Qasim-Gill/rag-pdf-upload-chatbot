{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMCEvjlC5pcQ9SwzQkzaH67",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Qasim-Gill/rag-pdf-upload-chatbot/blob/main/rag_exercise_for_company_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXFNM98RKIQE",
        "outputId": "0449a01c-320c-4b7b-a2b3-022561562fb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q pymupdf sentence-transformers faiss-cpu transformers langchain pdfplumber streamlit gdown\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import fitz  # PyMuPDF\n",
        "import faiss\n",
        "import numpy as np\n",
        "import streamlit as st\n",
        "import gdown\n",
        "import pdfplumber\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "\n",
        "# Load Models\n",
        "print(\"🔄 Loading models...\")\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Embedding Model\n",
        "model_name = \"google/flan-t5-large\"  # LLM Model\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "print(\"✅ Models loaded successfully.\")\n",
        "\n",
        "# Define Google Drive file IDs\n",
        "pdf_links = [\n",
        "    \"1QxsNzr-9BsSFGlVEJFcuL63OF06-ssrp\"\n",
        "    # \"1CEam1bfUKukBv23K72mS7aGy10I5oJDN\",\n",
        "    # \"1yW3kxVc5ruoIzKp37thGHWoAPoTjTlOD\",\n",
        "    # \"1oRzbim1rmgd3dOQT55QSI40MmZv0jTSr\"\n",
        "]\n",
        "\n",
        "# Directory to store PDFs\n",
        "pdf_dir = \"rag_company_pdfs\"\n",
        "os.makedirs(pdf_dir, exist_ok=True)\n",
        "\n",
        "# Extract text from PDFs\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    try:\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            text = \"\\n\".join([page.extract_text() or \"\" for page in pdf.pages])\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error extracting text from {pdf_path}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Process PDFs\n",
        "chunks = []\n",
        "for file_id in pdf_links:\n",
        "    pdf_path = os.path.join(pdf_dir, f\"{file_id}.pdf\")\n",
        "    gdown.download(f\"https://drive.google.com/uc?id={file_id}\", pdf_path, quiet=False)\n",
        "\n",
        "    if not os.path.exists(pdf_path):\n",
        "        print(f\"❌ PDF {pdf_path} was not downloaded correctly.\")\n",
        "        continue\n",
        "\n",
        "    pdf_text = extract_text_from_pdf(pdf_path)\n",
        "    if not pdf_text.strip():\n",
        "        print(f\"❌ No text extracted from {pdf_path}, skipping.\")\n",
        "        continue\n",
        "\n",
        "    # Chunking text\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=100)\n",
        "    pdf_chunks = text_splitter.split_text(pdf_text)\n",
        "\n",
        "    if not pdf_chunks:\n",
        "        print(f\"❌ No chunks created for {pdf_path}, skipping.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"✅ {len(pdf_chunks)} chunks created.\")\n",
        "    chunks.extend(pdf_chunks)\n",
        "\n",
        "if not chunks:\n",
        "    print(\"❌ No text chunks available for processing. Exiting...\")\n",
        "else:\n",
        "    print(f\"✅ Total {len(chunks)} chunks created across all PDFs.\")\n",
        "\n",
        "# Generate embeddings for all chunks\n",
        "if chunks:\n",
        "    print(\"🔄 Generating embeddings...\")\n",
        "    embeddings = np.array([embed_model.encode(chunk) for chunk in chunks], dtype=np.float32)\n",
        "    print(f\"✅ Generated {embeddings.shape[0]} embeddings of dimension {embeddings.shape[1]}\")\n",
        "else:\n",
        "    print(\"❌ No chunks found, skipping embeddings.\")\n",
        "\n",
        "# Store embeddings in FAISS\n",
        "if embeddings.shape[0] > 0:\n",
        "    dimension = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(dimension)\n",
        "    index.add(embeddings)\n",
        "    print(f\"✅ Added {index.ntotal} embeddings to FAISS index.\")\n",
        "else:\n",
        "    print(\"❌ No embeddings available, FAISS index not created.\")\n",
        "\n",
        "# Retrieve Relevant Chunks (Improved Re-ranking)\n",
        "def retrieve_relevant_chunks(query, top_k=8):\n",
        "    query_embedding = embed_model.encode(query).reshape(1, -1).astype(np.float32)\n",
        "    print(f\"🔎 Searching FAISS for query: {query}\")\n",
        "\n",
        "    _, indices = index.search(query_embedding, top_k)\n",
        "    retrieved = [chunks[i] for i in indices[0] if i < len(chunks)]\n",
        "\n",
        "    # Re-rank based on similarity score\n",
        "    chunk_embeddings = [embed_model.encode(chunk) for chunk in retrieved]\n",
        "    similarities = [util.pytorch_cos_sim(embed_model.encode(query), emb)[0][0].item() for emb in chunk_embeddings]\n",
        "\n",
        "    # Sort by highest similarity\n",
        "    sorted_chunks = [chunk for _, chunk in sorted(zip(similarities, retrieved), reverse=True)]\n",
        "\n",
        "    print(f\"✅ Retrieved {len(sorted_chunks)} chunks\")\n",
        "    for i, chunk in enumerate(sorted_chunks[:3]):  # Show top 3 chunks in logs\n",
        "        print(f\"Chunk {i+1}: {chunk[:200]}...\")\n",
        "\n",
        "    return sorted_chunks[:3]  # Keep only the top 3 most relevant chunks\n",
        "\n",
        "# Generate Answer with FLAN-T5 (More Context + Detailed Response)\n",
        "def generate_answer(question, context):\n",
        "    if not context.strip():\n",
        "        return \"⚠️ No relevant information found in the documents.\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    The following is information from company policy documents.\n",
        "    Use the given context to answer the question as accurately and fully as possible.\n",
        "\n",
        "    Context: {context}\n",
        "    Question: {question}\n",
        "\n",
        "    Answer the question in detail, ensuring that the explanation is thorough and user-friendly.\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
        "    outputs = model.generate(**inputs, max_length=768, do_sample=True, top_p=0.95, temperature=0.7)  # Increased max tokens\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"📄 PDF Chatbot with RAG\")\n",
        "st.subheader(\"Ask a question based on the company PDFs\")\n",
        "\n",
        "user_question = st.text_input(\"Ask a question:\")\n",
        "if st.button(\"Get Answer\") and user_question:\n",
        "    retrieved_chunks = retrieve_relevant_chunks(user_question)\n",
        "    context = \" \".join(retrieved_chunks)\n",
        "    answer = generate_answer(user_question, context)\n",
        "\n",
        "    if answer.strip():\n",
        "        st.write(\"**Answer:**\", answer)\n",
        "    else:\n",
        "        st.write(\"⚠️ No relevant answer found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgIn6DNAP_Et",
        "outputId": "70166528-b754-48bc-8bf9-694f4b2a3470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Loading models...\n",
            "✅ Models loaded successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QxsNzr-9BsSFGlVEJFcuL63OF06-ssrp\n",
            "To: /content/rag_company_pdfs/1QxsNzr-9BsSFGlVEJFcuL63OF06-ssrp.pdf\n",
            "100%|██████████| 450k/450k [00:00<00:00, 6.23MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 146 chunks created.\n",
            "✅ Total 146 chunks created across all PDFs.\n",
            "🔄 Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-02-14 13:37:04.182 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-14 13:37:04.183 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-14 13:37:04.187 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-14 13:37:04.189 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-14 13:37:04.192 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-14 13:37:04.193 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-14 13:37:04.194 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-14 13:37:04.195 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-14 13:37:04.197 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-14 13:37:04.198 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-14 13:37:04.199 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-14 13:37:04.200 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-14 13:37:04.201 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-14 13:37:04.203 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-14 13:37:04.204 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Generated 146 embeddings of dimension 384\n",
            "✅ Added 146 embeddings to FAISS index.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -qO- ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxtqfJOpS6Lp",
        "outputId": "93be2315-4cf0-4809-c4ae-8e944b268645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.16.163.174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2zBershS9jK",
        "outputId": "eb257b89-7fe3-48f9-9194-fc60f3eefe8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.16.163.174:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0Kyour url is: https://swift-ghosts-warn.loca.lt\n",
            "2025-02-14 13:38:06.327255: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739540286.351159   19463 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739540286.358675   19463 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "🔄 Loading models...\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "✅ Models loaded successfully.\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QxsNzr-9BsSFGlVEJFcuL63OF06-ssrp\n",
            "To: /content/rag_company_pdfs/1QxsNzr-9BsSFGlVEJFcuL63OF06-ssrp.pdf\n",
            "100% 450k/450k [00:00<00:00, 6.48MB/s]\n",
            "✅ 146 chunks created.\n",
            "✅ Total 146 chunks created across all PDFs.\n",
            "🔄 Generating embeddings...\n",
            "✅ Generated 146 embeddings of dimension 384\n",
            "✅ Added 146 embeddings to FAISS index.\n",
            "2025-02-14 13:38:24.196 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "🔄 Loading models...\n",
            "✅ Models loaded successfully.\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QxsNzr-9BsSFGlVEJFcuL63OF06-ssrp\n",
            "To: /content/rag_company_pdfs/1QxsNzr-9BsSFGlVEJFcuL63OF06-ssrp.pdf\n",
            "100% 450k/450k [00:00<00:00, 6.17MB/s]\n",
            "✅ 146 chunks created.\n",
            "✅ Total 146 chunks created across all PDFs.\n",
            "🔄 Generating embeddings...\n",
            "✅ Generated 146 embeddings of dimension 384\n",
            "✅ Added 146 embeddings to FAISS index.\n",
            "🔄 Loading models...\n",
            "✅ Models loaded successfully.\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QxsNzr-9BsSFGlVEJFcuL63OF06-ssrp\n",
            "To: /content/rag_company_pdfs/1QxsNzr-9BsSFGlVEJFcuL63OF06-ssrp.pdf\n",
            "100% 450k/450k [00:00<00:00, 5.40MB/s]\n",
            "✅ 146 chunks created.\n",
            "✅ Total 146 chunks created across all PDFs.\n",
            "🔄 Generating embeddings...\n",
            "✅ Generated 146 embeddings of dimension 384\n",
            "✅ Added 146 embeddings to FAISS index.\n",
            "🔎 Searching FAISS for query: what if i met with an accident with given company car ?\n",
            "✅ Retrieved 8 chunks\n",
            "Chunk 1: ■ Allowing unauthorized people to drive a company car, unless an emergency\n",
            "mandates it.\n",
            "On our part, we will ensure that our cars are safe and in good condition, as well as\n",
            "appropriately insured.\n",
            "Acci...\n",
            "Chunk 2: drivers.)\n",
            "■ Receive it as a benefit attached to your job.\n",
            "Either way, your car belongs to our company. You may use your company vehicle for\n",
            "personal reasons as our policy permits. You will get reimbur...\n",
            "Chunk 3: responsibility or guarantee payment to another person without authorization.\n",
            "Follow this policy’s guidelines to avoid disciplinary action. For minor offenses, like\n",
            "allowing unauthorized people to driv...\n",
            "🔄 Loading models...\n",
            "✅ Models loaded successfully.\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QxsNzr-9BsSFGlVEJFcuL63OF06-ssrp\n",
            "To: /content/rag_company_pdfs/1QxsNzr-9BsSFGlVEJFcuL63OF06-ssrp.pdf\n",
            "100% 450k/450k [00:00<00:00, 5.87MB/s]\n",
            "✅ 146 chunks created.\n",
            "✅ Total 146 chunks created across all PDFs.\n",
            "🔄 Generating embeddings...\n",
            "✅ Generated 146 embeddings of dimension 384\n",
            "✅ Added 146 embeddings to FAISS index.\n",
            "🔄 Loading models...\n",
            "✅ Models loaded successfully.\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QxsNzr-9BsSFGlVEJFcuL63OF06-ssrp\n",
            "To: /content/rag_company_pdfs/1QxsNzr-9BsSFGlVEJFcuL63OF06-ssrp.pdf\n",
            "100% 450k/450k [00:00<00:00, 5.94MB/s]\n",
            "✅ 146 chunks created.\n",
            "✅ Total 146 chunks created across all PDFs.\n",
            "🔄 Generating embeddings...\n",
            "✅ Generated 146 embeddings of dimension 384\n",
            "✅ Added 146 embeddings to FAISS index.\n",
            "🔎 Searching FAISS for query: how many sick leaves i can get ?\n",
            "✅ Retrieved 8 chunks\n",
            "Chunk 1: additional day of PTO that you must take within [12 months] after that holiday.\n",
            "We [will/ won’t] count hours you worked on a holiday to decide whether you are entitled\n",
            "to overtime pay.\n",
            "Sick leave\n",
            "We o...\n",
            "Chunk 2: take sick leave to recover from short-term illness, injuries, mental issues and other\n",
            "indisposition. If you have the flu or other contagious disease, please use your sick days.\n",
            "If you become sick, inf...\n",
            "Chunk 3: Use your PTO or arrange for a flexible work schedule if you want to attend routine\n",
            "health care (e.g. doctor’s/dentist’s appointments.)\n",
            "Occasionally, we may ask you to submit a physician’s note or othe...\n",
            "🔄 Loading models...\n",
            "✅ Models loaded successfully.\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QxsNzr-9BsSFGlVEJFcuL63OF06-ssrp\n",
            "To: /content/rag_company_pdfs/1QxsNzr-9BsSFGlVEJFcuL63OF06-ssrp.pdf\n",
            "100% 450k/450k [00:00<00:00, 5.98MB/s]\n",
            "✅ 146 chunks created.\n",
            "✅ Total 146 chunks created across all PDFs.\n",
            "🔄 Generating embeddings...\n",
            "✅ Generated 146 embeddings of dimension 384\n",
            "✅ Added 146 embeddings to FAISS index.\n",
            "🔄 Loading models...\n",
            "✅ Models loaded successfully.\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QxsNzr-9BsSFGlVEJFcuL63OF06-ssrp\n",
            "To: /content/rag_company_pdfs/1QxsNzr-9BsSFGlVEJFcuL63OF06-ssrp.pdf\n",
            "100% 450k/450k [00:00<00:00, 5.59MB/s]\n",
            "✅ 146 chunks created.\n",
            "✅ Total 146 chunks created across all PDFs.\n",
            "🔄 Generating embeddings...\n",
            "✅ Generated 146 embeddings of dimension 384\n",
            "✅ Added 146 embeddings to FAISS index.\n",
            "🔎 Searching FAISS for query: can i use cell phone on workspace ?\n",
            "✅ Retrieved 8 chunks\n",
            "Chunk 1: goods.\n",
            "Cell phone\n",
            "We allow use of cell phones at work. But, we also want to ensure that your devices\n",
            "won’t distract you from your work or disrupt our workplace. We ask you to follow a few\n",
            "simple rules...\n",
            "Chunk 2: not to disturb your colleagues.\n",
            "■ Avoid playing games on your phone or texting excessively.\n",
            "■ Avoid using your phone for any reason while driving a company vehicle.\n",
            "■ Don’t use your phone to record co...\n",
            "Chunk 3: If your job doesn’t require you to be present at our premises, you can occasionally work\n",
            "from home (WFH). We normally allow [one day per week.] If you need to telecommute\n",
            "for more days per week, talk ...\n",
            "🔄 Loading models...\n",
            "✅ Models loaded successfully.\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QxsNzr-9BsSFGlVEJFcuL63OF06-ssrp\n",
            "To: /content/rag_company_pdfs/1QxsNzr-9BsSFGlVEJFcuL63OF06-ssrp.pdf\n",
            "100% 450k/450k [00:00<00:00, 6.31MB/s]\n",
            "✅ 146 chunks created.\n",
            "✅ Total 146 chunks created across all PDFs.\n",
            "🔄 Generating embeddings...\n",
            "✅ Generated 146 embeddings of dimension 384\n",
            "✅ Added 146 embeddings to FAISS index.\n",
            "🔄 Loading models...\n",
            "✅ Models loaded successfully.\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QxsNzr-9BsSFGlVEJFcuL63OF06-ssrp\n",
            "To: /content/rag_company_pdfs/1QxsNzr-9BsSFGlVEJFcuL63OF06-ssrp.pdf\n",
            "100% 450k/450k [00:00<00:00, 6.33MB/s]\n",
            "✅ 146 chunks created.\n",
            "✅ Total 146 chunks created across all PDFs.\n",
            "🔄 Generating embeddings...\n",
            "✅ Generated 146 embeddings of dimension 384\n",
            "✅ Added 146 embeddings to FAISS index.\n",
            "🔎 Searching FAISS for query: can i come in neeker ?\n",
            "✅ Retrieved 8 chunks\n",
            "Chunk 1: our company, we may have to [transfer one of you.]\n",
            "Workplace visitors\n",
            "If you want to invite a visitor to our offices, please ask for permission from our [HR\n",
            "Manager/ Security Officer/ Office Manager] ...\n",
            "Chunk 2: xii. Select the most suitable candidate.\n",
            "xiii. Make an official offer.\n",
            "Steps may overlap, so skip steps when appropriate. Each member of a hiring team\n",
            "might have different responsibilities (e.g. recru...\n",
            "Chunk 3: ■ Be hired as permanent full- or part-time employees (not as temporary employees\n",
            "or contractors.)\n",
            "Our company may use an online form or a platform where employees may refer\n",
            "candidates. You can also re...\n",
            "🔄 Loading models...\n",
            "✅ Models loaded successfully.\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QxsNzr-9BsSFGlVEJFcuL63OF06-ssrp\n",
            "To: /content/rag_company_pdfs/1QxsNzr-9BsSFGlVEJFcuL63OF06-ssrp.pdf\n",
            "100% 450k/450k [00:00<00:00, 6.19MB/s]\n",
            "✅ 146 chunks created.\n",
            "✅ Total 146 chunks created across all PDFs.\n",
            "🔄 Generating embeddings...\n",
            "✅ Generated 146 embeddings of dimension 384\n",
            "✅ Added 146 embeddings to FAISS index.\n",
            "🔄 Loading models...\n",
            "✅ Models loaded successfully.\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QxsNzr-9BsSFGlVEJFcuL63OF06-ssrp\n",
            "To: /content/rag_company_pdfs/1QxsNzr-9BsSFGlVEJFcuL63OF06-ssrp.pdf\n",
            "100% 450k/450k [00:00<00:00, 6.29MB/s]\n",
            "✅ 146 chunks created.\n",
            "✅ Total 146 chunks created across all PDFs.\n",
            "🔄 Generating embeddings...\n",
            "✅ Generated 146 embeddings of dimension 384\n",
            "✅ Added 146 embeddings to FAISS index.\n",
            "🔎 Searching FAISS for query: can i come in shorts at office?\n",
            "✅ Retrieved 8 chunks\n",
            "Chunk 1: Dress code\n",
            "Our company’s official dress code is [Business/ Business Casual/ Smart Casual/\n",
            "Casual.] This includes [slacks/ loafers/ blouses/ boots.] However, an employee’s\n",
            "position may also inform how ...\n",
            "Chunk 2: soon as possible. We will excuse unreported absences in cases of [serious accidents,\n",
            "acute medical emergencies.] But, whenever possible, we should know when you won’t\n",
            "be coming in.\n",
            "Workplace policies\n",
            "...\n",
            "Chunk 3: our company, we may have to [transfer one of you.]\n",
            "Workplace visitors\n",
            "If you want to invite a visitor to our offices, please ask for permission from our [HR\n",
            "Manager/ Security Officer/ Office Manager] ...\n"
          ]
        }
      ]
    }
  ]
}